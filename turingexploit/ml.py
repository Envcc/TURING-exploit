# turingexploit/ml.py

import numpy as np

def reinforcement_learning(graph, capacities, alpha=0.1, gamma=0.9, epsilon=0.1, episodes=1000):
    nodes = list(graph.keys())
    q_table = {node: {neighbor: 0 for neighbor in graph[node]} for node in nodes}

    for _ in range(episodes):
        state = 'A'
        while state != 'D':
            if np.random.rand() < epsilon:
                action = np.random.choice(list(graph[state].keys()))
            else:
                action = max(q_table[state], key=q_table[state].get)
            
            next_state = action
            reward = capacities.get((state, next_state), 0)
            future_rewards = max(q_table[next_state].values()) if next_state in q_table else 0

            q_table[state][action] = q_table[state][action] + alpha * (reward + gamma * future_rewards - q_table[state][action])
            state = next_state

    optimal_policy = {}
    for state in q_table:
        optimal_policy[state] = max(q_table[state], key=q_table[state].get)
    
    return optimal_policy

# turingexploit/analysis.py

def bayesian_update(prior, likelihood, evidence):
    return (likelihood * prior) / evidence

def markov_chain(transitions, start_state, steps):
    current_state = start_state
    states = [current_state]

    for _ in range(steps):
        next_state = np.random.choice(list(transitions[current_state].keys()), 
                                      p=list(transitions[current_state].values()))
        states.append(next_state)
        current_state = next_state

    return states

def monte_carlo_simulation(graph, iterations=1000):
    results = []
    for _ in range(iterations):
        current_state = 'A'
        path = [current_state]
        while current_state != 'D':
            neighbors = list(graph[current_state].keys())
            current_state = np.random.choice(neighbors)
            path.append(current_state)
        results.append(path)
    return results

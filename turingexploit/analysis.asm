section .data
    ; Bayesian Update Data
    prior dd 0.5
    likelihood dd 0.8
    evidence dd 0.9
    result dd 0.0

    ; Markov Chain Data
    num_states db 3
    transitions db 0.1, 0.6, 0.3   ; State 0 transitions
               db 0.4, 0.4, 0.2    ; State 1 transitions
               db 0.7, 0.2, 0.1    ; State 2 transitions
    steps db 10
    result_markov db 10 dup(0)

    ; Monte Carlo Simulation Data
    iterations dd 1000
    graph db 'A', 'B', 'C', 'D', 0
    current_state db 'A'
    path db 256 dup(0)
    results db 1024 dup(0)
    seed dd 0

section .bss
    current_state resb 1
    random_number resd 1

section .text
    extern srand
    extern rand
    global _start

_start:
    ; Seed the random number generator using system time
    call get_time
    mov [seed], eax
    push eax
    call srand

    ; Call Bayesian update function
    call bayesian_update

    ; Call Markov Chain function
    call markov_chain

    ; Call Monte Carlo Simulation function
    call monte_carlo_simulation

    ; Exit the program
    call end_program

get_time:
    mov eax, 13        ; syscall: time
    xor ebx, ebx       ; argument: NULL
    int 0x80
    ret

bayesian_update:
    ; Bayesian Update: result = (likelihood * prior) / evidence
    fld dword [likelihood]
    fld dword [prior]
    fmulp st1, st0
    fld dword [evidence]
    fdivp st1, st0
    fstp dword [result]
    ret

markov_chain:
    ; Initialize Markov Chain
    mov byte [current_state], 0
    mov ecx, [steps]
    xor edi, edi

markov_loop:
    ; Get current state and transition probabilities
    movzx eax, byte [current_state]
    lea esi, [transitions + eax * num_states]

    ; Generate random number
    call rand
    cdq
    xor edx, edx
    mov ecx, 100
    div ecx
    mov ecx, eax

    ; Map random number to transition probabilities
    xor ebx, ebx
    mov bl, byte [esi]
    cmp ecx, ebx
    jb set_next_state_0

    mov bl, byte [esi + 1]
    add ebx, byte [esi]
    cmp ecx, ebx
    jb set_next_state_1

    mov byte [current_state], 2
    jmp store_state

set_next_state_0:
    mov byte [current_state], 0
    jmp store_state

set_next_state_1:
    mov byte [current_state], 1

store_state:
    mov al, byte [current_state]
    mov byte [result_markov + edi], al
    inc edi
    loop markov_loop
    ret

monte_carlo_simulation:
    ; Initialize Monte Carlo Simulation
    mov ecx, [iterations]
    xor edi, edi

monte_carlo_loop:
    mov byte [current_state], 'A'
    lea esi, [path]

monte_carlo_inner_loop:
    ; Add current state to path
    mov al, byte [current_state]
    stosb

    ; Check if current state is 'D'
    cmp al, 'D'
    je monte_carlo_store_result

    ; Get random neighbor
    call get_random_neighbor

    mov byte [current_state], al
    jmp monte_carlo_inner_loop

monte_carlo_store_result:
    ; Store path in results
    mov ecx, esi
    sub ecx, path
    rep movsb
    inc edi
    loop monte_carlo_loop
    ret

get_random_neighbor:
    ; Get neighbors from the graph
    movzx eax, byte [current_state]
    lea esi, [graph + eax * 4]
    mov ebx, 0

    ; Count neighbors
count_neighbors:
    mov al, byte [esi + ebx]
    test al, al
    jz done_counting
    inc ebx
    cmp ebx, 4
    jne count_neighbors

done_counting:
    ; Generate a random number and select a neighbor
    call rand
    cdq
    xor edx, edx
    div ebx
    movzx eax, al
    mov al, byte [esi + eax]
    ret

end_program:
    mov eax, 1         ; syscall: exit
    xor ebx, ebx
    int 0x80
